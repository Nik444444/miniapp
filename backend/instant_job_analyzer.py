"""
‚ö° Instant Job AI Analyzer - –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–π
–†–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–π —Å–µ—Ä–≤–∏—Å –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –≤–∞–∫–∞–Ω—Å–∏–π –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏:
- –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π AI –∞–Ω–∞–ª–∏–∑ –ø—Ä–∏ –ø—Ä–æ—Å–º–æ—Ç—Ä–µ —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
- –ü–æ–∫–∞–∑ % —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–π –≤–∞–∫–∞–Ω—Å–∏–∏
- –£–º–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥ –∫–ª—é—á–µ–≤—ã—Ö —á–∞—Å—Ç–µ–π –Ω–∞ –ø–æ–Ω—è—Ç–Ω—ã–π —è–∑—ã–∫
- –û–±—ä—è—Å–Ω–µ–Ω–∏–µ, –ø–æ—á–µ–º—É –≤–∞–∫–∞–Ω—Å–∏—è –ø–æ–¥—Ö–æ–¥–∏—Ç –∏–ª–∏ –Ω–µ –ø–æ–¥—Ö–æ–¥–∏—Ç
- –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä—ã
"""

import logging
import json
import asyncio
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
from modern_llm_manager import modern_llm_manager

logger = logging.getLogger(__name__)

class InstantJobAIAnalyzer:
    def __init__(self, database):
        self.db = database
        
        # –ö—ç—à –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_cache = {}
        self.cache_ttl = 3600  # 1 —á–∞—Å
        
        # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞ 
        self.quick_analysis_tokens = 800  # –ë—ã—Å—Ç—Ä—ã–π –∞–Ω–∞–ª–∏–∑
        self.full_analysis_tokens = 1500  # –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        
        # –¢–∏–ø—ã –∞–Ω–∞–ª–∏–∑–∞
        self.analysis_types = {
            'compatibility': '–ê–Ω–∞–ª–∏–∑ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏',
            'translation': '–£–º–Ω—ã–π –ø–µ—Ä–µ–≤–æ–¥',
            'explanation': '–û–±—ä—è—Å–Ω–µ–Ω–∏–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π',
            'improvement': '–°–æ–≤–µ—Ç—ã –ø–æ —É–ª—É—á—à–µ–Ω–∏—é',
            'salary': '–ê–Ω–∞–ª–∏–∑ –∑–∞—Ä–ø–ª–∞—Ç—ã',
            'company': '–ê–Ω–∞–ª–∏–∑ –∫–æ–º–ø–∞–Ω–∏–∏'
        }
    
    async def instant_job_analysis(self,
                                 job_data: Dict[str, Any],
                                 user_profile: Dict[str, Any],
                                 analysis_type: str = 'compatibility',
                                 language: str = 'ru',
                                 user_providers: List[Tuple[str, str, str]] = None) -> Dict[str, Any]:
        """
        ‚ö° –ú–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –≤–∞–∫–∞–Ω—Å–∏–∏
        """
        try:
            # –°–æ–∑–¥–∞–µ–º –∫–ª—é—á –∫—ç—à–∞
            cache_key = self._create_cache_key(job_data, user_profile, analysis_type)
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à
            cached_result = self._get_cached_analysis(cache_key)
            if cached_result:
                logger.info(f"‚ö° Using cached analysis for job {job_data.get('title', 'Unknown')}")
                return cached_result
            
            logger.info(f"‚ö° Starting instant analysis for job: {job_data.get('title', 'Unknown')}")
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑
            analysis_result = await self._perform_instant_analysis(
                job_data, user_profile, analysis_type, language, user_providers
            )
            
            # –ö—ç—à–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
            self._cache_analysis(cache_key, analysis_result)
            
            return {
                'status': 'success',
                'analysis': analysis_result,
                'analysis_type': analysis_type,
                'cached': False,
                'timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"Instant job analysis failed: {e}")
            return {
                'status': 'error',
                'message': f'–û—à–∏–±–∫–∞ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}',
                'fallback_analysis': self._create_fallback_analysis(job_data, user_profile, analysis_type)
            }
    
    async def batch_instant_analysis(self,
                                   jobs_list: List[Dict[str, Any]],
                                   user_profile: Dict[str, Any],
                                   language: str = 'ru',
                                   user_providers: List[Tuple[str, str, str]] = None) -> List[Dict[str, Any]]:
        """
        üöÄ –ü–∞–∫–µ—Ç–Ω—ã–π –º–≥–Ω–æ–≤–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–ø–∏—Å–∫–∞ –≤–∞–∫–∞–Ω—Å–∏–π
        """
        try:
            logger.info(f"üöÄ Starting batch analysis for {len(jobs_list)} jobs")
            
            # –°–æ–∑–¥–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            analysis_tasks = []
            for job in jobs_list[:20]:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º 20 –≤–∞–∫–∞–Ω—Å–∏—è–º–∏ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
                task = self.instant_job_analysis(
                    job, user_profile, 'compatibility', language, user_providers
                )
                analysis_tasks.append(task)
            
            # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ —Å —Ç–∞–π–º–∞—É—Ç–æ–º
            results = await asyncio.gather(*analysis_tasks, return_exceptions=True)
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
            analyzed_jobs = []
            for i, result in enumerate(results):
                if isinstance(result, Exception):
                    logger.error(f"Job analysis {i} failed: {result}")
                    # –î–æ–±–∞–≤–ª—è–µ–º fallback –∞–Ω–∞–ª–∏–∑
                    analyzed_jobs.append({
                        'job': jobs_list[i],
                        'analysis': self._create_fallback_analysis(jobs_list[i], user_profile, 'compatibility'),
                        'error': True
                    })
                else:
                    analyzed_jobs.append({
                        'job': jobs_list[i],
                        'analysis': result.get('analysis', {}),
                        'error': False
                    })
            
            return analyzed_jobs
            
        except Exception as e:
            logger.error(f"Batch instant analysis failed: {e}")
            # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –≤–∞–∫–∞–Ω—Å–∏–∏ —Å fallback –∞–Ω–∞–ª–∏–∑–æ–º
            return [
                {
                    'job': job,
                    'analysis': self._create_fallback_analysis(job, user_profile, 'compatibility'),
                    'error': True
                }
                for job in jobs_list
            ]
    
    async def _perform_instant_analysis(self,
                                      job_data: Dict[str, Any],
                                      user_profile: Dict[str, Any],
                                      analysis_type: str,
                                      language: str,
                                      user_providers: List[Tuple[str, str, str]] = None) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        if not user_providers:
            return self._create_fallback_analysis(job_data, user_profile, analysis_type)
        
        # –°–æ–∑–¥–∞–µ–º —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç
        prompt = self._create_instant_analysis_prompt(job_data, user_profile, analysis_type, language)
        
        try:
            provider, model, api_key = user_providers[0]
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –±—ã—Å—Ç—Ä—ã–µ —Ç–æ–∫–µ–Ω—ã –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
            max_tokens = self.quick_analysis_tokens if analysis_type == 'compatibility' else self.full_analysis_tokens
            
            ai_analysis = await modern_llm_manager.generate_content(
                prompt=prompt,
                provider=provider,
                model=model,
                api_key=api_key,
                max_tokens=max_tokens
            )
            
            return self._parse_instant_analysis(ai_analysis, job_data, user_profile, analysis_type)
            
        except Exception as e:
            logger.error(f"AI instant analysis failed: {e}")
            return self._create_fallback_analysis(job_data, user_profile, analysis_type)
    
    def _create_instant_analysis_prompt(self,
                                      job_data: Dict[str, Any],
                                      user_profile: Dict[str, Any],
                                      analysis_type: str,
                                      language: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–ª—è –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        job_info = f"""
–í–∞–∫–∞–Ω—Å–∏—è: {job_data.get('title', 'Unknown')}
–ö–æ–º–ø–∞–Ω–∏—è: {job_data.get('company_name', 'Unknown')}
–û–ø–∏—Å–∞–Ω–∏–µ: {job_data.get('description', 'No description')[:300]}...
–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è: {job_data.get('requirements', 'No requirements')}
–ó–∞—Ä–ø–ª–∞—Ç–∞: {job_data.get('salary', 'Not specified')}
–õ–æ–∫–∞—Ü–∏—è: {job_data.get('location', 'Unknown')}
"""
        
        profile_summary = self._create_profile_summary(user_profile)
        
        if analysis_type == 'compatibility':
            return self._create_compatibility_prompt(job_info, profile_summary, language)
        elif analysis_type == 'translation':
            return self._create_translation_prompt(job_info, language)
        elif analysis_type == 'explanation':
            return self._create_explanation_prompt(job_info, language)
        elif analysis_type == 'improvement':
            return self._create_improvement_prompt(job_info, profile_summary, language)
        else:
            return self._create_compatibility_prompt(job_info, profile_summary, language)
    
    def _create_compatibility_prompt(self, job_info: str, profile_summary: str, language: str) -> str:
        """–ü—Ä–æ–º–ø—Ç –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏"""
        
        if language == 'ru':
            return f"""
–¢—ã —ç–∫—Å–ø–µ—Ä—Ç-—Ä–µ–∫—Ä—É—Ç–µ—Ä. –ë—ã—Å—Ç—Ä–æ –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å –∫–∞–Ω–¥–∏–¥–∞—Ç–∞ —Å –≤–∞–∫–∞–Ω—Å–∏–µ–π.

–í–ê–ö–ê–ù–°–ò–Ø:
{job_info}

–ü–†–û–§–ò–õ–¨ –ö–ê–ù–î–ò–î–ê–¢–ê:
{profile_summary}

–î–∞–π –ú–ì–ù–û–í–ï–ù–ù–´–ô –∞–Ω–∞–ª–∏–∑ (–º–∞–∫—Å–∏–º—É–º 200 —Å–ª–æ–≤):

1. –°–û–í–ú–ï–°–¢–ò–ú–û–°–¢–¨ (0-100%): –¢–æ—á–Ω—ã–π –±–∞–ª–ª —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
2. –ö–õ–Æ–ß–ï–í–´–ï –ü–õ–Æ–°–´: 2-3 –≥–ª–∞–≤–Ω—ã—Ö –ø—Ä–µ–∏–º—É—â–µ—Å—Ç–≤–∞ –∫–∞–Ω–¥–∏–¥–∞—Ç–∞
3. –û–°–ù–û–í–ù–´–ï –ú–ò–ù–£–°–´: 1-2 –≥–ª–∞–≤–Ω—ã—Ö –Ω–µ–¥–æ—Å—Ç–∞—Ç–∫–∞ –∏–ª–∏ –ø—Ä–æ–±–µ–ª–∞
4. –®–ê–ù–°–´ –£–°–ü–ï–•–ê: –†–µ–∞–ª—å–Ω–∞—è –æ—Ü–µ–Ω–∫–∞ –ø–æ–ª—É—á–µ–Ω–∏—è –∏–Ω—Ç–µ—Ä–≤—å—é/–æ—Ñ—Ñ–µ—Ä–∞
5. –û–î–ù–ê –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–Ø: –°–∞–º—ã–π –≤–∞–∂–Ω—ã–π —Å–æ–≤–µ—Ç –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è –∫–∞–Ω–¥–∏–¥–∞—Ç—É—Ä—ã

–ë—É–¥—å –∫—Ä–∞—Ç–æ–∫, –∫–æ–Ω–∫—Ä–µ—Ç–µ–Ω –∏ —á–µ—Å—Ç–µ–Ω. –û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
"""
        else:
            return f"""
You're an expert recruiter. Quickly analyze candidate-job compatibility.

JOB:
{job_info}

CANDIDATE PROFILE:
{profile_summary}

Give INSTANT analysis (max 200 words):

1. COMPATIBILITY (0-100%): Exact compatibility score
2. KEY STRENGTHS: 2-3 main candidate advantages  
3. MAIN WEAKNESSES: 1-2 main gaps or weaknesses
4. SUCCESS CHANCES: Realistic assessment for interview/offer
5. ONE RECOMMENDATION: Most important advice to improve candidacy

Be brief, specific and honest. Response in JSON format.
"""
    
    def _create_translation_prompt(self, job_info: str, language: str) -> str:
        """–ü—Ä–æ–º–ø—Ç –¥–ª—è —É–º–Ω–æ–≥–æ –ø–µ—Ä–µ–≤–æ–¥–∞"""
        
        if language == 'ru':
            return f"""
–ü–µ—Ä–µ–≤–µ–¥–∏ –∫–ª—é—á–µ–≤—ã–µ —á–∞—Å—Ç–∏ –≤–∞–∫–∞–Ω—Å–∏–∏ –Ω–∞ —Ä—É—Å—Å–∫–∏–π —è–∑—ã–∫ –ø—Ä–æ—Å—Ç—ã–º, –ø–æ–Ω—è—Ç–Ω—ã–º —è–∑—ã–∫–æ–º.

–í–ê–ö–ê–ù–°–ò–Ø:
{job_info}

–ü–µ—Ä–µ–≤–µ–¥–∏ –∏ –æ–±—ä—è—Å–Ω–∏:
1. –ù–ê–ó–í–ê–ù–ò–ï –ò –†–û–õ–¨: –ß—Ç–æ –∏–º–µ–Ω–Ω–æ –¥–µ–ª–∞–µ—Ç —ç—Ç–æ—Ç —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç
2. –ö–õ–Æ–ß–ï–í–´–ï –¢–†–ï–ë–û–í–ê–ù–ò–Ø: –°–∞–º—ã–µ –≤–∞–∂–Ω—ã–µ –Ω–∞–≤—ã–∫–∏ –∏ –æ–ø—ã—Ç (–ø—Ä–æ—Å—Ç—ã–º–∏ —Å–ª–æ–≤–∞–º–∏)
3. –û–ë–Ø–ó–ê–ù–ù–û–°–¢–ò: –û—Å–Ω–æ–≤–Ω—ã–µ –∑–∞–¥–∞—á–∏ –Ω–∞ —Ä–∞–±–æ—Ç–µ
4. –£–°–õ–û–í–ò–Ø: –ó–∞—Ä–ø–ª–∞—Ç–∞, –≥—Ä–∞—Ñ–∏–∫, –ª—å–≥–æ—Ç—ã
5. –ö–û–ú–ü–ê–ù–ò–Ø: –ö—Ç–æ —Ç–∞–∫–∏–µ –∏ —á–µ–º –∑–∞–Ω–∏–º–∞—é—Ç—Å—è

–ò–∑–±–µ–≥–∞–π –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–æ–≥–æ –∂–∞—Ä–≥–æ–Ω–∞. –û–±—ä—è—Å–Ω—è–π –∫–∞–∫ –æ–±—ã—á–Ω–æ–º—É —á–µ–ª–æ–≤–µ–∫—É.
–û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
"""
        else:
            return f"""
Translate key parts of the job posting into simple, understandable {language}.

JOB:
{job_info}

Translate and explain:
1. TITLE & ROLE: What exactly this specialist does
2. KEY REQUIREMENTS: Most important skills and experience (in simple terms)
3. RESPONSIBILITIES: Main job tasks
4. CONDITIONS: Salary, schedule, benefits  
5. COMPANY: Who they are and what they do

Avoid professional jargon. Explain to a regular person.
Response in JSON format.
"""
    
    def _create_improvement_prompt(self, job_info: str, profile_summary: str, language: str) -> str:
        """–ü—Ä–æ–º–ø—Ç –¥–ª—è —Å–æ–≤–µ—Ç–æ–≤ –ø–æ —É–ª—É—á—à–µ–Ω–∏—é"""
        
        if language == 'ru':
            return f"""
–î–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Å–æ–≤–µ—Ç—ã, –∫–∞–∫ –∫–∞–Ω–¥–∏–¥–∞—Ç—É —É–ª—É—á—à–∏—Ç—å —Å–≤–æ–∏ —à–∞–Ω—Å—ã –Ω–∞ —ç—Ç—É –≤–∞–∫–∞–Ω—Å–∏—é.

–í–ê–ö–ê–ù–°–ò–Ø:
{job_info}

–ü–†–û–§–ò–õ–¨ –ö–ê–ù–î–ò–î–ê–¢–ê:
{profile_summary}

–î–∞–π 5 –ö–û–ù–ö–†–ï–¢–ù–´–• —Å–æ–≤–µ—Ç–æ–≤:

1. –ù–ê–í–´–ö–ò: –ö–∞–∫–∏–µ –Ω–∞–≤—ã–∫–∏ —Å—Ä–æ—á–Ω–æ –Ω—É–∂–Ω–æ –ø–æ–¥—Ç—è–Ω—É—Ç—å
2. –û–ü–´–¢: –ö–∞–∫–æ–π –æ–ø—ã—Ç/–ø—Ä–æ–µ–∫—Ç—ã –º–æ–∂–Ω–æ –ø–æ–ª—É—á–∏—Ç—å –±—ã—Å—Ç—Ä–æ
3. CV: –ö–∞–∫ –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å —Ä–µ–∑—é–º–µ –ø–æ–¥ —ç—Ç—É –≤–∞–∫–∞–Ω—Å–∏—é
4. –ü–û–î–ì–û–¢–û–í–ö–ê: –ß—Ç–æ –∏–∑—É—á–∏—Ç—å –ø–µ—Ä–µ–¥ –∏–Ω—Ç–µ—Ä–≤—å—é
5. –°–ï–¢–¨: –ö–∞–∫ –Ω–∞–π—Ç–∏ —Å–≤—è–∑–∏ –≤ —ç—Ç–æ–π –∫–æ–º–ø–∞–Ω–∏–∏/–∏–Ω–¥—É—Å—Ç—Ä–∏–∏

–ö–∞–∂–¥—ã–π —Å–æ–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –î–ï–ô–°–¢–í–ï–ù–ù–´–ú –∏ –ö–û–ù–ö–†–ï–¢–ù–´–ú.
–û—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.
"""
        else:
            return f"""
Give specific advice on how the candidate can improve their chances for this job.

JOB:
{job_info}

CANDIDATE PROFILE:  
{profile_summary}

Give 5 SPECIFIC tips:

1. SKILLS: Which skills urgently need improvement
2. EXPERIENCE: What experience/projects can be gained quickly
3. CV: How to rewrite resume for this job
4. PREPARATION: What to study before interview
5. NETWORK: How to find connections in this company/industry

Each tip should be ACTIONABLE and SPECIFIC.
Response in JSON format.
"""
    
    def _create_profile_summary(self, user_profile: Dict[str, Any]) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫—Ä–∞—Ç–∫–æ–≥–æ —Ä–µ–∑—é–º–µ –ø—Ä–æ—Ñ–∏–ª—è"""
        
        collected_data = user_profile.get('collected_data', {})
        
        return f"""
–ü—Ä–æ—Ñ–µ—Å—Å–∏—è: {collected_data.get('profession', 'Unknown')}
–û–ø—ã—Ç: {collected_data.get('experience_years', 'Unknown')} –ª–µ—Ç
–ù–∞–≤—ã–∫–∏: {', '.join(collected_data.get('technical_skills', ['Not specified']))}
–ù–µ–º–µ—Ü–∫–∏–π: {collected_data.get('german_level', 'Unknown')}
–ì–æ—Ä–æ–¥: {collected_data.get('preferred_city', 'Unknown')}
–ó–∞—Ä–ø–ª–∞—Ç–∞: {collected_data.get('salary_expectations', 'Unknown')}
–§–æ—Ä–º–∞—Ç —Ä–∞–±–æ—Ç—ã: {collected_data.get('work_format', 'Unknown')}
"""
    
    def _parse_instant_analysis(self,
                              ai_analysis: str,
                              job_data: Dict[str, Any],
                              user_profile: Dict[str, Any],
                              analysis_type: str) -> Dict[str, Any]:
        """–ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –º–≥–Ω–æ–≤–µ–Ω–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"""
        
        try:
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å JSON
            if '{' in ai_analysis and '}' in ai_analysis:
                json_start = ai_analysis.find('{')
                json_end = ai_analysis.rfind('}') + 1
                json_str = ai_analysis[json_start:json_end]
                parsed = json.loads(json_str)
                
                # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
                parsed['analysis_type'] = analysis_type
                parsed['job_title'] = job_data.get('title', 'Unknown')
                parsed['company'] = job_data.get('company_name', 'Unknown')
                parsed['analyzed_at'] = datetime.now().isoformat()
                
                return parsed
        except:
            pass
        
        # Fallback –ø–∞—Ä—Å–∏–Ω–≥
        return self._extract_fallback_data(ai_analysis, analysis_type)
    
    def _extract_fallback_data(self, ai_analysis: str, analysis_type: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∏–∑ —Ç–µ–∫—Å—Ç–æ–≤–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ –∫–∞–∫ fallback"""
        
        base_data = {
            'analysis_type': analysis_type,
            'raw_analysis': ai_analysis[:500] + '...' if len(ai_analysis) > 500 else ai_analysis,
            'analyzed_at': datetime.now().isoformat()
        }
        
        if analysis_type == 'compatibility':
            # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å –ø—Ä–æ—Ü–µ–Ω—Ç —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏
            import re
            percentage_match = re.search(r'(\d+)%', ai_analysis)
            compatibility_score = int(percentage_match.group(1)) if percentage_match else 75
            
            base_data.update({
                'compatibility_score': compatibility_score,
                'key_strengths': ['–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω', '–ù–∞–π–¥–µ–Ω—ã —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è'],
                'main_weaknesses': ['–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞'],
                'success_chances': '–°—Ä–µ–¥–Ω–∏–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—ã',
                'recommendation': '–†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–¥–∞—á—É –∑–∞—è–≤–∫–∏'
            })
        
        return base_data
    
    def _create_fallback_analysis(self,
                                job_data: Dict[str, Any],
                                user_profile: Dict[str, Any],
                                analysis_type: str) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–Ω–∏–µ fallback –∞–Ω–∞–ª–∏–∑–∞ –ø—Ä–∏ –æ—à–∏–±–∫–µ AI"""
        
        collected_data = user_profile.get('collected_data', {})
        
        if analysis_type == 'compatibility':
            # –ü—Ä–æ—Å—Ç–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç–∏ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
            job_title = job_data.get('title', '').lower()
            job_desc = job_data.get('description', '').lower()
            profession = collected_data.get('profession', '').lower()
            skills = collected_data.get('technical_skills', [])
            
            # –ë–∞–∑–æ–≤–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
            compatibility_score = 50
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä–æ—Ñ–µ—Å—Å–∏—é –≤ –Ω–∞–∑–≤–∞–Ω–∏–∏
            if profession in job_title:
                compatibility_score += 30
            elif profession in job_desc:
                compatibility_score += 20
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–≤—ã–∫–∏
            skill_matches = 0
            for skill in skills:
                if skill.lower() in job_desc or skill.lower() in job_title:
                    skill_matches += 1
            
            compatibility_score += min(skill_matches * 5, 20)
            compatibility_score = min(compatibility_score, 100)
            
            return {
                'compatibility_score': compatibility_score,
                'key_strengths': [
                    f'–û–ø—ã—Ç –≤ –æ–±–ª–∞—Å—Ç–∏ {profession}',
                    f'–ù–∞–≤—ã–∫–∏: {", ".join(skills[:3])}' if skills else '–û–±—â–∏–µ –Ω–∞–≤—ã–∫–∏'
                ],
                'main_weaknesses': [
                    '–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–µ—Ç–∞–ª—å–Ω–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π',
                    '–†–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫–∞'
                ],
                'success_chances': '–°—Ä–µ–¥–Ω–∏–µ' if compatibility_score >= 70 else '–ù–∏–∑–∫–∏–µ',
                'recommendation': '–í–Ω–∏–º–∞—Ç–µ–ª—å–Ω–æ –∏–∑—É—á–∏—Ç–µ —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è –∏ –ø–æ–¥–≥–æ—Ç–æ–≤—å—Ç–µ —Å–∏–ª—å–Ω–æ–µ —Å–æ–ø—Ä–æ–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ–µ –ø–∏—Å—å–º–æ',
                'analysis_type': 'fallback_compatibility',
                'fallback_mode': True
            }
        
        # –î–ª—è –¥—Ä—É–≥–∏—Ö —Ç–∏–ø–æ–≤ –∞–Ω–∞–ª–∏–∑–∞
        return {
            'analysis_type': analysis_type,
            'fallback_mode': True,
            'message': '–ê–Ω–∞–ª–∏–∑ –≤—ã–ø–æ–ª–Ω–µ–Ω –≤ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ',
            'job_title': job_data.get('title', 'Unknown'),
            'company': job_data.get('company_name', 'Unknown')
        }
    
    # =====================================================
    # –ö–≠–®–ò–†–û–í–ê–ù–ò–ï
    # =====================================================
    
    def _create_cache_key(self,
                         job_data: Dict[str, Any],
                         user_profile: Dict[str, Any],
                         analysis_type: str) -> str:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–ª—é—á–∞ –∫—ç—à–∞"""
        
        job_key = f"{job_data.get('title', '')}-{job_data.get('company_name', '')}"
        profile_key = f"{user_profile.get('collected_data', {}).get('profession', '')}"
        
        return f"{analysis_type}:{hash(job_key)}:{hash(profile_key)}"
    
    def _get_cached_analysis(self, cache_key: str) -> Optional[Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –∏–∑ –∫—ç—à–∞"""
        
        if cache_key in self.analysis_cache:
            cached_data = self.analysis_cache[cache_key]
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º TTL
            cache_time = datetime.fromisoformat(cached_data['cached_at'])
            if (datetime.now() - cache_time).seconds < self.cache_ttl:
                cached_data['from_cache'] = True
                return cached_data
            else:
                # –£–¥–∞–ª—è–µ–º —É—Å—Ç–∞—Ä–µ–≤—à–∏–π –∫—ç—à
                del self.analysis_cache[cache_key]
        
        return None
    
    def _cache_analysis(self, cache_key: str, analysis_result: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –∞–Ω–∞–ª–∏–∑–∞ –≤ –∫—ç—à"""
        
        analysis_result['cached_at'] = datetime.now().isoformat()
        self.analysis_cache[cache_key] = analysis_result
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º —Ä–∞–∑–º–µ—Ä –∫—ç—à–∞
        if len(self.analysis_cache) > 1000:
            # –£–¥–∞–ª—è–µ–º —Å—Ç–∞—Ä—ã–µ –∑–∞–ø–∏—Å–∏
            oldest_keys = sorted(
                self.analysis_cache.keys(),
                key=lambda k: self.analysis_cache[k].get('cached_at', ''),
            )[:100]
            
            for key in oldest_keys:
                del self.analysis_cache[key]

# –°–æ–∑–¥–∞–µ–º –≥–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä
instant_job_analyzer = None

def get_instant_job_analyzer(database):
    global instant_job_analyzer
    if instant_job_analyzer is None:
        instant_job_analyzer = InstantJobAIAnalyzer(database)
    return instant_job_analyzer