import os
import asyncio
import logging
from typing import Dict, Any, Optional, Tuple
from abc import ABC, abstractmethod
import google.generativeai as genai
import openai
from anthropic import Anthropic
import httpx
from pathlib import Path
from PIL import Image
import tempfile
import base64

logger = logging.getLogger(__name__)

class LLMProvider(ABC):
    """–ê–±—Å—Ç—Ä–∞–∫—Ç–Ω—ã–π –∫–ª–∞—Å—Å –¥–ª—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ LLM"""

    def __init__(self, api_key: str, model_name: str):
        self.api_key = api_key
        self.model_name = model_name
        self.name = self.__class__.__name__

    @abstractmethod
    async def generate_content(self, prompt: str, image_path: Optional[str] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω—ã–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ–º"""
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        pass

class GeminiProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Google Gemini"""

    def __init__(self, api_key: str, model_name: str = "gemini-1.5-flash"):
        super().__init__(api_key, model_name)
        if api_key:
            genai.configure(api_key=api_key)
            self.model = genai.GenerativeModel(model_name)
        else:
            self.model = None

    async def generate_content(self, prompt: str, image_path: Optional[str] = None) -> str:
        try:
            if not self.model:
                raise Exception("Gemini API key not configured")

            if image_path:
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
                image = Image.open(image_path)
                response = await asyncio.get_event_loop().run_in_executor(
                    None, self.model.generate_content, [prompt, image]
                )
            else:
                response = await asyncio.get_event_loop().run_in_executor(
                    None, self.model.generate_content, prompt
                )

            return response.text
        except Exception as e:
            logger.error(f"Gemini generation error: {e}")
            raise Exception(f"Gemini error: {str(e)}")

    def is_available(self) -> bool:
        return bool(self.api_key and self.model)

class OpenAIProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è OpenAI"""

    def __init__(self, api_key: str, model_name: str = "gpt-4o-mini"):
        super().__init__(api_key, model_name)
        if api_key:
            self.client = openai.AsyncOpenAI(api_key=api_key)
        else:
            self.client = None

    async def generate_content(self, prompt: str, image_path: Optional[str] = None) -> str:
        try:
            if not self.client:
                raise Exception("OpenAI API key not configured")

            messages = [{"role": "user", "content": prompt}]

            if image_path:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64
                with open(image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode()

                messages[0]["content"] = [
                    {"type": "text", "text": prompt},
                    {"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"}}
                ]

            response = await self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                max_tokens=1500
            )

            return response.choices[0].message.content
        except Exception as e:
            logger.error(f"OpenAI generation error: {e}")
            raise Exception(f"OpenAI error: {str(e)}")

    def is_available(self) -> bool:
        return bool(self.api_key and self.client)

class AnthropicProvider(LLMProvider):
    """–ü—Ä–æ–≤–∞–π–¥–µ—Ä –¥–ª—è Anthropic Claude"""

    def __init__(self, api_key: str, model_name: str = "claude-3-haiku-20240307"):
        super().__init__(api_key, model_name)
        if api_key:
            self.client = Anthropic(api_key=api_key)
        else:
            self.client = None

    async def generate_content(self, prompt: str, image_path: Optional[str] = None) -> str:
        try:
            if not self.client:
                raise Exception("Anthropic API key not configured")

            if image_path:
                # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –≤ base64
                with open(image_path, "rb") as image_file:
                    base64_image = base64.b64encode(image_file.read()).decode()

                message = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.client.messages.create(
                        model=self.model_name,
                        max_tokens=1500,
                        messages=[{
                            "role": "user",
                            "content": [
                                {"type": "text", "text": prompt},
                                {"type": "image", "source": {"type": "base64", "media_type": "image/jpeg", "data": base64_image}}
                            ]
                        }]
                    )
                )
            else:
                message = await asyncio.get_event_loop().run_in_executor(
                    None,
                    lambda: self.client.messages.create(
                        model=self.model_name,
                        max_tokens=1500,
                        messages=[{"role": "user", "content": prompt}]
                    )
                )

            return message.content[0].text
        except Exception as e:
            logger.error(f"Anthropic generation error: {e}")
            raise Exception(f"Anthropic error: {str(e)}")

    def is_available(self) -> bool:
        return bool(self.api_key and self.client)

class LLMManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä –¥–ª—è —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏ LLM"""

    def __init__(self):
        self.providers: Dict[str, LLMProvider] = {}
        self.initialize_providers()

    def initialize_providers(self):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è"""
        try:
            # Gemini
            gemini_key = os.environ.get('GEMINI_API_KEY')
            if gemini_key:
                self.providers['gemini'] = GeminiProvider(gemini_key)

            # OpenAI
            openai_key = os.environ.get('OPENAI_API_KEY')
            if openai_key:
                self.providers['openai'] = OpenAIProvider(openai_key)

            # Anthropic
            anthropic_key = os.environ.get('ANTHROPIC_API_KEY')
            if anthropic_key:
                self.providers['anthropic'] = AnthropicProvider(anthropic_key)

            logger.info(f"Initialized {len(self.providers)} LLM providers")
        except Exception as e:
            logger.error(f"Failed to initialize providers: {e}")

    def get_provider_status(self) -> Dict[str, Dict[str, Any]]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ –≤—Å–µ—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        status = {}
        for name, provider in self.providers.items():
            status[name] = {
                "status": "active" if provider.is_available() else "inactive",
                "model": provider.model_name,
                "name": provider.name
            }

        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –±–µ–∑ –∫–ª—é—á–µ–π
        all_providers = ['gemini', 'openai', 'anthropic']
        for provider_name in all_providers:
            if provider_name not in status:
                status[provider_name] = {
                    "status": "inactive",
                    "model": "N/A",
                    "name": f"{provider_name.title()}Provider"
                }

        return status

    def create_user_provider(self, provider_type: str, model_name: str, api_key: str) -> LLMProvider:
        """–°–æ–∑–¥–∞–Ω–∏–µ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ —Å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º API –∫–ª—é—á–æ–º"""
        if provider_type.lower() == 'gemini':
            return GeminiProvider(api_key, model_name)
        elif provider_type.lower() == 'openai':
            return OpenAIProvider(api_key, model_name)
        elif provider_type.lower() == 'anthropic':
            return AnthropicProvider(api_key, model_name)
        else:
            raise ValueError(f"Unsupported provider type: {provider_type}")

    async def generate_content(self, prompt: str, image_path: Optional[str] = None) -> Tuple[str, str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–º –≤—ã–±–æ—Ä–æ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞"""
        active_providers = [name for name, provider in self.providers.items() if provider.is_available()]

        if not active_providers:
            # –ï—Å–ª–∏ –Ω–µ—Ç –∞–∫—Ç–∏–≤–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –∑–∞–≥–ª—É—à–∫—É
            return "–î–µ–º–æ –∞–Ω–∞–ª–∏–∑: –≠—Ç–æ —Ç–µ—Å—Ç–æ–≤—ã–π –æ—Ç–≤–µ—Ç. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –Ω–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á–∏ –¥–ª—è –ø–æ–ª–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏.", "Demo"

        # –ü–æ–ø—Ä–æ–±—É–µ–º –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –≤ –ø–æ—Ä—è–¥–∫–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        priority_order = ['gemini', 'openai', 'anthropic']

        for provider_name in priority_order:
            if provider_name in active_providers:
                try:
                    provider = self.providers[provider_name]
                    response = await provider.generate_content(prompt, image_path)
                    return response, provider_name.title()
                except Exception as e:
                    logger.warning(f"Provider {provider_name} failed: {e}")
                    continue

        # –ï—Å–ª–∏ –≤—Å–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ —Å—Ä–∞–±–æ—Ç–∞–ª–∏, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–µ–º–æ –∞–Ω–∞–ª–∏–∑
        logger.info("All providers failed, returning demo analysis")
        return self._create_demo_analysis(prompt), "Demo"
    
    def _create_demo_analysis(self, prompt: str) -> str:
        """–°–æ–∑–¥–∞–µ—Ç –¥–µ–º–æ –∞–Ω–∞–ª–∏–∑ –∫–æ–≥–¥–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –ø—Ä–æ–≤–∞–π–¥–µ—Ä—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã"""
        return """
üìÑ –î–ï–ú–û –ê–ù–ê–õ–ò–ó –î–û–ö–£–ú–ï–ù–¢–ê

üìù –ö–†–ê–¢–ö–û–ï –†–ï–ó–Æ–ú–ï:
–î–æ–∫—É–º–µ–Ω—Ç –ø–æ–ª—É—á–µ–Ω –∏ –æ–±—Ä–∞–±–æ—Ç–∞–Ω –≤ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ. –î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–æ–ª–Ω–æ–≥–æ AI-–∞–Ω–∞–ª–∏–∑–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å API –∫–ª—é—á–∏.

üè¢ –ò–ù–§–û–†–ú–ê–¶–ò–Ø –û–ë –û–¢–ü–†–ê–í–ò–¢–ï–õ–ï:
–ê–Ω–∞–ª–∏–∑ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏

üìã –¢–ò–ü –î–û–ö–£–ú–ï–ù–¢–ê:
–¢–∏–ø –¥–æ–∫—É–º–µ–Ω—Ç–∞ –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç—Å—è –≤ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∞–Ω–∞–ª–∏–∑–∞

üìä –û–°–ù–û–í–ù–û–ï –°–û–î–ï–†–ñ–ê–ù–ò–ï:
–ü–æ–¥—Ä–æ–±–Ω—ã–π –∞–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è –¥–æ—Å—Ç—É–ø–µ–Ω —Å –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω—ã–º–∏ API –∫–ª—é—á–∞–º–∏

‚úÖ –¢–†–ï–ë–£–ï–ú–´–ï –î–ï–ô–°–¢–í–ò–Ø:
- –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –ø–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
- –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∫ –∞–¥–º–∏–Ω–∏—Å—Ç—Ä–∞—Ç–æ—Ä—É –¥–ª—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–∏—Å—Ç–µ–º—ã

üìÖ –í–ê–ñ–ù–´–ï –°–†–û–ö–ò:
–ê–Ω–∞–ª–∏–∑ —Å—Ä–æ–∫–æ–≤ –¥–æ—Å—Ç—É–ø–µ–Ω –≤ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏

‚ö†Ô∏è –í–û–ó–ú–û–ñ–ù–´–ï –ü–û–°–õ–ï–î–°–¢–í–ò–Ø:
–û—Ü–µ–Ω–∫–∞ —Ä–∏—Å–∫–æ–≤ –ø—Ä–æ–≤–æ–¥–∏—Ç—Å—è —Å –∞–∫—Ç–∏–≤–Ω—ã–º–∏ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞–º–∏

üö® –£–†–û–í–ï–ù–¨ –°–†–û–ß–ù–û–°–¢–ò: 
–°—Ä–µ–¥–Ω–∏–π (–¥–µ–º–æ —Ä–µ–∂–∏–º)

üí° –†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò:
1. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ Gemini, OpenAI –∏–ª–∏ Anthropic API –∫–ª—é—á–∏
2. –ü–æ–≤—Ç–æ—Ä–Ω–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
3. –û–±—Ä–∞—Ç–∏—Ç–µ—Å—å –∑–∞ –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

üìß –®–ê–ë–õ–û–ù –û–¢–í–ï–¢–ê:
–ü–µ—Ä—Å–æ–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —à–∞–±–ª–æ–Ω—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–æ—Å—Ç—É–ø–Ω—ã –≤ –ø–æ–ª–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –∞–Ω–∞–ª–∏–∑–∞.

---
üîß –≠—Ç–æ –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ä–µ–∂–∏–º. –ù–∞—Å—Ç—Ä–æ–π—Ç–µ API –∫–ª—é—á–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ä–µ–∞–ª—å–Ω–æ–≥–æ AI-–∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.
        """.strip()

    def get_available_providers(self) -> Dict[str, bool]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –¥–æ—Å—Ç—É–ø–Ω—ã—Ö –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤"""
        return {name: provider.is_available() for name, provider in self.providers.items()}

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä –º–µ–Ω–µ–¥–∂–µ—Ä–∞
llm_manager = LLMManager()